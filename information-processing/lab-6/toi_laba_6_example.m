% Файл pr53_rec_gaus_uneq. Синтез и анализ алгоритмов распознавания ГСВ с 
% различными матрицами ковариации
clear all;
close all;
% Построить  график  зависимости  суммарной  экспериментальной  ошибки 
% первого рода ( для  третьего  класса)  от числа испытаний  (объема выборки ). 
% Сравнить с теоретическим  значением. 

% Нужно добавить вот эти строки
% KK = [100 500 1000 2000 5000 10000];    % разные значения объемов выборки
KK = 1000;
err1c3 = zeros(size(KK));                % ошибка первого рода третьего класса
err2c3 = zeros(size(KK));                % ошибка второго рода третьего класса

% Добавляется цикл по объемам выборки
for tt = 1 : numel(KK)  % цикл по объемам выборки
    %% 1. Задание исходных данных
    n = 2;
    M = 2; % размерность признакового пространства и число классов
    
    % МЕНЯЕТСЯ СЛЕДУЮЩАЯ СТРОЧКА : 
    K = KK(tt); % количество статистических испытаний
    
    % Априорные вероятности, математические ожидания и матрицы ковариации классов
    dm = 2.0; % расстояние между математическими ожиданиями классов по координатным осям
    C = [5 1; 1 5];
    C_ = C ^ -1; % матрица ковариации вектора признаков различных классов
    pw = [0.4 0.6 0.5];
    pw = pw / sum(pw);
    D = 3 * eye(2);
    m = [2 2; 1 -1;]';
   
    np = sum(pw);
    pw = pw / np; % исключение некорректного задания априорных вероятностей
    
    % + Этот пункт 1.1. Генерация обучающих выборок классов
    % число образов каждого класса
    Ks = fix(K * pw);
    Ks(end) = K - sum(Ks(1 : end - 1));
    for i = 1 : M % цикл по классам   
        XN{i} = repmat(m( : , i), [1, Ks(i)]) + randncor(n, Ks(i), C(i)); % генерация К образов i - го класса
    end
    
    %% 2. Расчет матриц вероятностей ошибок распознавания
    PIJ = zeros(M); PIJB = zeros(M); mg = zeros(M); Dg = zeros(M); l0_ = zeros(M);    
    for i = 1 : M
        for j = i + 1 : M
               dmij = m( : , i) - m( : , j); 
               l0_(i, j) = log(pw(j) / pw(i)); 
               dti = det(C(i)); dtj = det(C(j));
               trij = trace(C_(j) * C(i) - eye(n));
               trji = trace(eye(n) - C_(i) * C(j));
               mg1 = 0.5 * (trij + dmij' * C_(j) * dmij - log(dti / dtj)); 
               Dg1 = 0.5 * trij^2 + dmij' * C_(j) * C(i) * C_(j) * dmij; 
               mg2 = 0.5 * (trji - dmij' * C_(i) * dmij + log(dtj / dti)); 
               Dg2 = 0.5 * trji^2 + dmij' * C_(i) * C(j) * C_(i) * dmij; 
               sD1 = sqrt(Dg1); sD2 = sqrt(Dg2);
               PIJ(i, j) = normcdf(l0_(i, j), mg1, sD1);
               PIJ(j, i) = 1 - normcdf(l0_(i, j), mg2, sD2);
               mu2 = (1 / 8) * dmij' * ((C(i) / 2 + C(j) / 2)^ - 1) * dmij...
                   +0.5 * log((dti + dtj) / (2 * sqrt(dti * dtj))); % расстояние Бхатачария
               PIJB(i, j) = sqrt(pw(j) / pw(i)) * exp( - mu2);
               PIJB(j, i) = sqrt(pw(i) / pw(j)) * exp( - mu2); % границы Чернова
        end
        PIJB(i, i) = 1 - sum(PIJB(i, : ));
        PIJ(i, i) = 1 - sum(PIJ(i, : )); % нижняя граница вероятности правильного распознавания
    end
     
    % 2.1. Определение вероятностей ошибок методом скользящего контроля
    % Убрать отсюда всё, где есть Pc2 и p2_
	r = 0.5;
    kl_kernel = 11;	% параметры оценки Парзена
    Pc1 = zeros(M); % матрицы ошибок
    p1_ = zeros(M, 1);
    for i = 1 : M % реализация метода скользящего контроля
        N = Ks(i);
        XNi = XN{i}; XNi_ = zeros(n, N - 1);
        indi = [1 : i - 1, i + 1 : M];
        for j = 1 : N
            x = XNi( : , j); indj = [1 : j - 1, j + 1 : N]; % изъятие тестового образа i - го класса
            XNi_( : , 1 : j - 1) = XNi( : , 1 : j - 1); XNi_( : , j : end) = XNi( : , j + 1 : end);
            h_N = N^( - r / n); % размеры окна Парзена
            p1_(i) = vkernel(x, XNi_, h_N, 11); % оценка Парзена
            for t = 1 : M - 1
                 ij = indi(t);
                 h_N = Ks(ij)^( - r / n); % размеры окна Парзена
                 p1_(ij) = vkernel(x, XN{ij}, h_N, 11);
            end
            [ui1, iai1] = max(p1_);
            Pc1(i, iai1) = Pc1(i, iai1) + 1;
        end
        Pc1(i, : ) = Pc1(i, : ) / N;
    end
     
    %% 3. Тестирование алгоритма методом статистических испытаний
    Pcv = zeros(M);
    p = zeros(M, 1);
    
    x = ones(n, 1); u = zeros(M, 1);
    Pc_ = zeros(M); % экспериментальная матрица вероятностей ошибок
    for k = 1 : K % цикл по числу испытаний
        for i = 1 : M % цикл по классам
            [x, px] = randncor(n, 1, C(i)); x = x + m( : , i); % генерация образа i - го класса             
            for j = 1 : M % вычисление значения разделяющих функций
                u(j)= - 0.5 * (x - m( : , j))' * C_(j) * (x - m( : , j)) - 0.5 * log(det(C(j))) + log(pw(j));                
                h_N = Ks(j)^( - r / n); % размеры окна Парзена
                p(j) = vkernel(x, XN{j}, h_N, 11);
            end
            [~, iai] = max(u); % определение максимума
            Pc_(i, iai) = Pc_(i, iai) + 1; % фиксация результата распознавания
            
            [ui, iai] = max(p); % определение максимума
            Pcv(i, iai) = Pcv(i, iai) + 1; % фиксация результата распознавания
        end
    end
    Pc_ = Pc_ / K;
    Pcv = Pcv / K;
end % конец цикла по объемам выборки

% ТЕПЕРЬ визуализация зависимостей ошибок от объема выборки
% figure; hold on;    % новое графическое окно + режим дорисовки
% plot(KK, err1c3);   % график экспериментальной ошибки
% title('первый класс первый род');

% figure; hold on;    % новое графическое окно + режим дорисовки
% plot(KK, err2c3);   % график экспериментальной ошибки
% title('второй класс первый род');

disp('Теоретическая матрица вероятностей ошибок');disp(PIJ);
disp('Матрица ошибок по методу скользящего контроля');disp(Pc1);
disp('Матрица ошибок на основе границы Чернова');disp(PIJB);
disp('Экспериментальная матрица ошибок (с оценками Парзена)');disp(Pcv);







