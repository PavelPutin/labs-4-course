clear all; close all;
%%% Пример вар.5. Построить графики зависимостей ошибок от объема обучающей выборки.
% (a. гауссовская функция c использованием диагональной матрицы и гауссовская функция c использованием матрицы ковариаций)
%% Здесь только Двумерный случай

% ЗДЕСЬ задаются перебираемые занчения величины N (объема обучающей выборки)
NN = 1000 : 1000 : 10000;
% Массивы значений ошибок для каждого типа оконной функции
err1 = NN * 0;   % массив значений ошибок заполненный нулями
err2 = NN * 0;   % массив значений ошибок заполненный нулями

% ЗДЕСЬ добавляется цикл по числу элементов NN
for tt = 1 : numel(NN)
    % 1. Исходные данные
    n=2; %n-размерность вектора наблюдений
    % ЗДЕСЬ подставляем очередное значение из массива NN
    N=NN(tt); %количество используемых для оценки векторов
    r=0.5;
    h_N=N^(-r/n); %расчет параметра размера окна
    kl_kernel=12;%ключ выбора ядра оценки (см. описание функции vkernel)

    % 2.Генерация отсчетов эталонной плотности (в виде смеси гауссиан) для двумерного случая
    % Параметры распределения смеси гауссовских случайных векторов;
    M=3; %количество компонентов в смеси
    ps=[0.2,0.2,0.6]; %вероятности появления СВ различных типов в смеси
    % Расчет матрицы ковариаций ГСВ смеси
    D=0.2; ro=-log(0.7); %дисперсия и коэффициент корреляции cоседних элементов 
    % Расположение математических ожиданий компонентов смеси
    m1=[0;0]; m2=[1;0]; m3=[0;1]; m=[m1,m2,m3];
    % Ковариационная матрица компонентов смеси
    for i=1:n, for j=1:n,
            C(i,j)=D*exp(-ro*abs(i-j));
    end;end;
    x1=[-2:0.1:3]; x2= [-2:0.1:3]; %области значений СВ, для которой визуализируется оценка
    [X1,X2]=meshgrid(x1,x2); x=[X1(:) X2(:)]'; % матрицы Х и Y координат отсчётов
    % Значения эталонной плотности
    p=ps(1)*mvnpdf(x',m1',C)+ps(2)*mvnpdf(x',m2',C)+ps(3)*mvnpdf(x',m3',C);
    % pi=reshape(p,length(x1),length(x2));%матрица значений плотности распределения

    % 3. Убрать Отображение графика плотности распределения

    % 4. Обучающая выборка
    XN=zeros(n,N);
    for i=1:N,%генерация обучающей выборки 
         u=rand;
         %индекс принадлежности к компоненте смеси
         if u<ps(1), t=1; elseif u<ps(1)+ps(2), t=2; else t=3; end;
         XN(:,i)=randncor(n,1,C)+m(:,t);
    end;

    % 5. Оценка плотности по Парзену
    p_=vkernel(x,XN,h_N,kl_kernel);%оценка плотности
    %Матрица значений  оценки плотности распределения
    % pv=reshape(p_,length(x1),length(x2));

    % 3. ЗДЕСЬ Оценки плотности по Парзену с заданными видами оконной функции
    p1=vkernel(x,XN,h_N,11);%оценка плотности (гауссовская функция c использованием диагональной матрицы)
    p2=vkernel(x,XN,h_N,12);%оценка плотности (гауссовская функция c использованием матрицы ковариаций)

    % ЗДЕСЬ фиксируем среднеквадратичную ошибку
    err1(tt) = sqrt(mean((p(:) - p1(:)) .^ 2));
    err2(tt) = sqrt(mean((p(:) - p2(:)) .^ 2));
end
% ЗДЕСЬ вместо п.4. выводим зависимость ошибки от объема обучающей выборки
figure;
plot(NN, err1, '-r', NN, err2, '-g');
legend('гаус (диаг. ков. мат)', 'гаус (выбороч. ков. мат.)');
% Какая кривая ниже всех - такое окно и лучше
